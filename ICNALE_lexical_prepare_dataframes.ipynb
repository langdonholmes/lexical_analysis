{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "ICNALE_lexical_prepare_dataframes.ipynb",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/langdonholmes/lexical_analysis/blob/main/ICNALE_lexical_prepare_dataframes.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Preparing dataframes\n",
        "\n",
        "Working with thousands of separate text files can be cumbersome.  \n",
        "Preparing .csv files with the texts and metadata is a simple alternative."
      ],
      "metadata": {
        "id": "XAm-hu-hvvhj"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rvtRBe4PumvS"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import pathlib\n",
        "import pandas as pd"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Texts to Dataframe\n"
      ],
      "metadata": {
        "id": "Xzlul-CXu-dF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "corpus_dir = '/content/drive/MyDrive/data/icnale_bert_lexical/ICNALE_W_single_folder_cleaned/'\n",
        "meta_data = '/content/drive/MyDrive/data/icnale_bert_lexical/final_icnale_variable_smoking_lme.csv'\n",
        "smj_only = '/content/drive/MyDrive/data/icnale_bert_lexical/smj.csv'\n",
        "\n",
        "if not os.path.isfile(smj_only):\n",
        "    texts = []\n",
        "    for file in tqdm(pathlib.Path(corpus_dir).rglob(\"*.txt\")):\n",
        "        with open(file, 'r', encoding=\"utf-8\") as f: \n",
        "            text = f.read()\n",
        "            texts.append((file.name, text))\n",
        "    df = pd.DataFrame.from_records(texts, columns=['Filename', 'text'])\n",
        "    df = df.merge(pd.read_csv(meta_data), on='Filename')\n",
        "    df.to_csv(smj_only)"
      ],
      "metadata": {
        "id": "UM5872qHu6We"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Train Valid Split on Smoking Prompt\n",
        "\n",
        "Later on, we will be finetuning BERT, which means that we need a train/test split.  \n",
        "We do that here so that all our methods use the same train/test split."
      ],
      "metadata": {
        "id": "vTdp2FlXvGdl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train_valid = ['/content/drive/MyDrive/data/icnale_bert_lexical/smj_train.csv',\n",
        "               '/content/drive/MyDrive/data/icnale_bert_lexical/smj_valid.csv']\n",
        "\n",
        "if not os.path.isfile(train_valid[0]):\n",
        "    df = pd.read_csv(fname, index_col=0)\n",
        "    train, validandtest = train_test_split(\n",
        "        df,\n",
        "        test_size=.2,\n",
        "        stratify=df['Country'],\n",
        "        random_state=42)\n",
        "    for fname, pandaframe in zip(train_valid, [train, validandtest]):\n",
        "      if not os.path.isfile(fname):\n",
        "        pandaframe.to_csv(fname)"
      ],
      "metadata": {
        "id": "5qBySJkku8Aa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Augment training data with part time job prompt\n",
        "\n",
        "all_incale_for_bert_training.csv was produced on my PC. I should include the original dataset."
      ],
      "metadata": {
        "id": "2x3iyHchvKRJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "all_icnale = '/content/drive/MyDrive/data/icnale_bert_lexical/all_icnale_for_bert_training.csv'\n",
        "both_prompts_but_no_validation = '/content/drive/MyDrive/data/icnale_bert_lexical/all_icnale_train.csv'\n",
        "if not os.path.isfile(both_prompts_but_no_validation):\n",
        "    df = pd.read_csv('/content/drive/MyDrive/data/icnale_bert_lexical/smj_valid.csv', index_col=0)\n",
        "    all = pd.read_csv(all_icnale, index_col=0)\n",
        "    all = all[all['VST'].notna()].reset_index()\n",
        "    all_train = all[~all['Filename'].isin(df['Filename'])]\n",
        "    all_train.to_csv(both_prompts_but_no_validation, index=False)"
      ],
      "metadata": {
        "id": "Ug9VB5dsu84w"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Get to know your data\n",
        "This is just a quick and dirty test to get a point of reference.  \n",
        "We wil run the final analysis in R, after verifying the assumptions of a linear model."
      ],
      "metadata": {
        "id": "grasrpjAxqen"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn import linear_model\n",
        "\n",
        "def ball_park():\n",
        "  predictors = ['LD_Mean_RT_CW', 'Kuperman_AoA_CW', 'WN_Mean_RT_CW',\n",
        "                'aoe_index_above_threshold_40', 'PLD_CW', 'mtld_original_cw',\n",
        "                'hdd42_cw', 'McD_CD_CW', 'Brysbaert_Concreteness_Combined_CW',\n",
        "                'COCA_magazine_bi_DP']\n",
        "\n",
        "  smj_train = '/content/drive/MyDrive/data/icnale_bert_lexical/smj_train.csv'\n",
        "  smj_valid = '/content/drive/MyDrive/data/icnale_bert_lexical/smj_valid.csv'\n",
        "\n",
        "  train = pd.read_csv(smj_train, index_col=0)\n",
        "  valid = pd.read_csv(smj_valid, index_col=0)\n",
        "  X_train = train[predictors]\n",
        "  X_test = valid[predictors]\n",
        "  y_train = train['VST']\n",
        "  y_test = valid['VST']\n",
        "\n",
        "  lin = linear_model.LinearRegression()\n",
        "  lin.fit(X_train, y_train)\n",
        "  return lin.score(X_test, y_test) # R Squared\n",
        "\n",
        "print(f'Ordinary Least Squares (OLS) predicts with an R Squared of {ball_park():.3f}.')\n",
        "print('This is based on linguistic features generated with TAALES output.')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ppiyNN3txr-V",
        "outputId": "7deaac30-18d6-4a3d-9dee-584f36cde969"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Ordinary Least Squares (OLS) predicts with an R Squared of 0.173.\n",
            "This is based on linguistic features generated with TAALES output.\n"
          ]
        }
      ]
    }
  ]
}