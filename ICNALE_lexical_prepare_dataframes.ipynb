{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "view-in-github"
   },
   "source": [
    "<a href=\"https://colab.research.google.com/github/langdonholmes/lexical_analysis/blob/main/ICNALE_lexical_prepare_dataframes.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "XAm-hu-hvvhj"
   },
   "source": [
    "# Preparing dataframes\n",
    "\n",
    "Working with thousands of separate text files can be cumbersome.  \n",
    "Preparing .csv files with the texts and metadata is a simple alternative."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "rvtRBe4PumvS"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import pathlib\n",
    "import pandas as pd\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Xzlul-CXu-dF"
   },
   "source": [
    "## Texts to Dataframe\n",
    "Using the ICNALE corpus WE24 retrieved in 2020"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "8b9ggIvj3YOD"
   },
   "outputs": [],
   "source": [
    "## Creates a corpus from a directory of text files\n",
    "corpus_dir = 'data/all_icnale_texts.csv'\n",
    "meta_data_path = 'data/WE24.csv'\n",
    "all_icnale_path = 'data/all_icnale_texts.csv'\n",
    "\n",
    "if not os.path.isfile(all_icnale_path):\n",
    "    texts = []\n",
    "    for file in tqdm(pathlib.Path(corpus_dir).rglob(\"*/*.txt\")):\n",
    "        with open(file, 'r', encoding=\"utf-8\") as f: \n",
    "            text = f.read()\n",
    "            texts.append((file.name, text))\n",
    "    all_texts_df = pd.DataFrame.from_records(texts, columns=['Filename', 'text'])\n",
    "\n",
    "    '''Filename: W_CHN_PTJ0_021_A2_0.txt --> Code: W_CHN_021'''\n",
    "    tmp_arr = (\n",
    "        all_texts_df['Filename']\n",
    "        .str.split('_', expand=True) # ['W', 'CHN', 'PTJ0', '021', 'A2', '0.txt']\n",
    "        )\n",
    "\n",
    "    all_texts_df['id'] = (\n",
    "        tmp_arr\n",
    "        .iloc[:, [0, 1, 3]] # ['W', 'CHN', '021']\n",
    "        .apply(lambda x: '_'.join(x), axis='columns') # 'W_CHN_021'\n",
    "    )\n",
    "    \n",
    "    all_texts_df['prompt'] = (tmp_arr.iloc[:, 2]) # 'PTJ0'\n",
    "    \n",
    "    info = pd.read_csv(meta_data_path)[['Code', 'VST']]\n",
    "    info = info.rename(columns={'Code':'id'})\n",
    "    all_texts_df = all_texts_df.merge(info, on='id', how='left')\n",
    "    all_texts_df.to_csv(all_icnale_path, index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "vTdp2FlXvGdl"
   },
   "source": [
    "## Train Test Split on Smoking Prompt\n",
    "\n",
    "Later on, we will be finetuning BERT, which means that we need a train/test split.  \n",
    "We do that here so that all our methods use the same train/test split.  \n",
    "smj.csv was prepared previously for another project."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "5qBySJkku8Aa"
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "smk_path = 'data/smk.csv'\n",
    "train_path = 'data/smk_train.csv'\n",
    "test_path = 'data/smk_test.csv'\n",
    "\n",
    "if not os.path.isfile(train_path):\n",
    "    df = pd.read_csv(smk_path)\n",
    "    train, test = train_test_split(\n",
    "        df,\n",
    "        test_size=.2,\n",
    "        stratify=df['Country'], # we do not want our split to have a bias towards one country or another\n",
    "        random_state=42)\n",
    "    train.to_csv(train_path, index=False)\n",
    "    test.to_csv(test_path, index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2x3iyHchvKRJ"
   },
   "source": [
    "## Augment training data with part time job prompt\n",
    "\n",
    "Reintroduce the PTJ0 prompt to the training set, but make sure that the test set stays clean."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "0JrTy80Dzsx9"
   },
   "outputs": [],
   "source": [
    "all_train_path = 'data/all_train.csv'\n",
    "\n",
    "if not os.path.isfile(all_train_path):\n",
    "    all_texts_df = pd.read_csv(all_icnale_path)\n",
    "    all_train = all_texts_df[~all_texts_df['Filename'].isin(test['Filename'])]\n",
    "    all_train.to_csv(all_train_path, index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "grasrpjAxqen"
   },
   "source": [
    "## Get to know your data\n",
    "This is just a quick and dirty test to get a point of reference.  \n",
    "We wil run the final analysis in R, after verifying the assumptions of a linear model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ppiyNN3txr-V",
    "outputId": "5c4ee509-342f-416f-c3ab-ed5ef30b226d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ordinary Least Squares (OLS) predicts with an R Squared of 0.173.\n",
      "This is based on linguistic features generated with TAALES output.\n"
     ]
    }
   ],
   "source": [
    "from sklearn import linear_model\n",
    "\n",
    "def ball_park():\n",
    "  predictors = ['LD_Mean_RT_CW', 'Kuperman_AoA_CW', 'WN_Mean_RT_CW',\n",
    "                'aoe_index_above_threshold_40', 'PLD_CW', 'mtld_original_cw',\n",
    "                'hdd42_cw', 'McD_CD_CW', 'Brysbaert_Concreteness_Combined_CW',\n",
    "                'COCA_magazine_bi_DP']\n",
    "\n",
    "  X_train = train[predictors]\n",
    "  X_test = test[predictors]\n",
    "  y_train = train['VST']\n",
    "  y_test = test['VST']\n",
    "\n",
    "  lin = linear_model.LinearRegression()\n",
    "  lin.fit(X_train, y_train)\n",
    "  return lin.score(X_test, y_test) # R Squared\n",
    "\n",
    "print(f'Ordinary Least Squares (OLS) predicts with an R Squared of {ball_park():.3f}.')\n",
    "print('This is based on linguistic features generated with TAALES output.')"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "include_colab_link": true,
   "name": "ICNALE_lexical_prepare_dataframes.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
